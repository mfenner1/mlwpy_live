{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80dce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.style.use('fivethirtyeight')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd0d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (datasets, dummy, ensemble,\n",
    "                     linear_model, metrics,\n",
    "                     model_selection as skms,\n",
    "                     naive_bayes, neighbors, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (make_learning_curve, make_complexity_curve, \n",
    "                   rms_error, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24b7aa",
   "metadata": {},
   "source": [
    "# Part 1:  Fit-Predict-Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad2d86",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "  * Part A:\n",
    "    * Read in the data from `datasets/housing_small.csv` using `pandas`.\n",
    "    * There is a target in the `Target` column.  Make that the output target and everything else the input features.\n",
    "    *  Build a 3-nearest neighbor model and train it on that entire dataset.\n",
    "    *  Make predictions on that same dataset.\n",
    "    *  Evaluate the predictions using root-mean-squared-error.\n",
    "  * Part B:\n",
    "    * Read in the data from `datasets/housing_small.csv` using `pandas`.\n",
    "    * There is a target in the `Target` column.  Make that the output target and everything else the input features.\n",
    "    * Make a training and testing set from that dataset.\n",
    "    * Build a 3-nearest neighbor model and train it on the training set.\n",
    "    * With that trained model, make predictions on both the training and testing sets.\n",
    "    * Evalute the predictions using root-mean-squared-error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edf1c66",
   "metadata": {},
   "source": [
    "### Part A: Simple sklearn (in-sample only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b098b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7cce672",
   "metadata": {},
   "source": [
    "### Part B: Simple sklearn (train-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9910af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbc46ab3",
   "metadata": {},
   "source": [
    "# Part 2:  Comparing Models on TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1632ba",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "  * Part A:\n",
    "    * On a train-test split built from `datasets/housing_small.csv`, fit and predict using a `dummy.DummyRegressor`.\n",
    "    * Compute the root-mean-squared-error (RMSE) for training and testing.\n",
    "  * Part B:\n",
    "    * Create a train-test split from `datasets/housing_small.csv`.\n",
    "    * Build and evaluate three different nearest neighbor models (by varying the number of neighbors) using RMSE.\n",
    "  * Part C:\n",
    "    * Create a train-test split from `datasets/housing_small.csv`.\n",
    "    * Build and evaluate three different decision tree models (by varying the depth of the tree) using RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b112aba",
   "metadata": {},
   "source": [
    "### Part A: Baseline `Predict-the-Mean` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386cb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a77c829",
   "metadata": {},
   "source": [
    "### Part B: Three k-Nearest Neighbors Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1113d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3c4200",
   "metadata": {},
   "source": [
    "### Part C: Three Decision Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef601f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a452e04",
   "metadata": {},
   "source": [
    "# Part 3: Cross-Validation and Model Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e593520",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "  * Part A:\n",
    "    * Use `skms.cross_val_score` (imported above) to evaluate the RMSE of a 3-nearest neighbors model on `datasets/housing_small.csv`.  You can use `scoring=rmse` to have `cross_val_score` return the necessary values.\n",
    "    * Use `skms.cross_val_score` to evaluate the RMSE of the models you built in Exercise 2.\n",
    "  * Part B:\n",
    "    * Still working with `datasets/housing_small.csv`, find a good value for the number of neighbors by using `make_complexity_curve`.\n",
    "    * With the good number of neighbors, generate a learning curve with `make_learning_curve`.\n",
    "  * Part C:\n",
    "    * Repeat Part B using a decision tree and finding a good max_depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764218b",
   "metadata": {},
   "source": [
    "### Part A: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574412e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bffb274",
   "metadata": {},
   "source": [
    "### Part B: A Good Hyper + A Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001fd697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f243248d",
   "metadata": {},
   "source": [
    "### Part C: A Good Hyper + A Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df2a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fd7b0ba",
   "metadata": {},
   "source": [
    "# Part 4: Now to Improve!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfca184",
   "metadata": {},
   "source": [
    "# Exercise 4:\n",
    "  *  Part A:\n",
    "      * We can train pretty well with more complex models, but they are overfitting. Can we use more examples to smooth things out?  Using the data in `datasets/housing_tall.csv`:\n",
    "        * Reevaluate our baseline mean-only model.\n",
    "        * Find a good nearest neighbors model and build a learning curve for it.\n",
    "        * Find a good decision tree model and build a learning curve for it.\n",
    "  *  Part B:\n",
    "      * Does adding more features improve our results?  We'll go back to fewer examples, but use a lot more features.  Using the data in `datasets/housing_wide.csv`:\n",
    "        * Find a good nearest neighbors model and build a learning curve for it.\n",
    "        * Find a good decision tree model and build a learning curve for it.\n",
    "  *  Part C (optional):\n",
    "      * Does it help to be selective about our features?  Using a `RandomForestRegressor` along with `feature_importances_` identify a top-10 set of features and use those to build a model.\n",
    "  *  Part D:\n",
    "      * Does using a lot of features and a lot of examples help?  Using the data in `datasets/housing_full.csv`:\n",
    "        * Find good nearest neighbor and decision tree models.\n",
    "        * (Optional) Determine if selecting a top-10 set of features (as in Part C) helps.\n",
    "  * Part E:\n",
    "    * How have we done overall?  Using the best model you found for `housing_wide.csv` or `housing_all.csv`, train that model on *all* of the data in that `.csv` file.  Evaluate that trained model on the data in `datasets/housing_hot_wide.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b3a4f",
   "metadata": {},
   "source": [
    "### Part A: More Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f95034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ed99b2e",
   "metadata": {},
   "source": [
    "### Part B: More Features (back to shorter dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a29002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53e8049a",
   "metadata": {},
   "source": [
    "### Part C: Let's Be Selective about our Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c96bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86bb35f6",
   "metadata": {},
   "source": [
    "### Part D:  All the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47695fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40d957e8",
   "metadata": {},
   "source": [
    "### Part E: Train on All Data and Evaluate on Hold-Out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca39345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
