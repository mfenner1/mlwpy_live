{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80dce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd0d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (datasets, dummy, ensemble,\n",
    "                     linear_model, metrics,\n",
    "                     model_selection as skms,\n",
    "                     naive_bayes, neighbors, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (make_learning_curve, make_complexity_curve, \n",
    "                   rms_error, rmse,\n",
    "                   manage_ames_nans, manage_ames_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24b7aa",
   "metadata": {},
   "source": [
    "# Part 1:  Fit-Predict-Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad2d86",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "  * Part A:\n",
    "    * Read in the data from `datasets/housing_small.csv` using `pandas`.\n",
    "    * There is a target in the `Target` column.  Make that the output target and everything else the input features.\n",
    "    *  Build a 3-nearest neighbor model and train it on that entire dataset.\n",
    "    *  Make predictions on that same dataset.\n",
    "    *  Evaluate the predictions using root-mean-squared-error.\n",
    "  * Part B:\n",
    "    * Read in the data from `datasets/housing_small.csv` using `pandas`.\n",
    "    * There is a target in the `Target` column.  Make that the output target and everything else the input features.\n",
    "    * Make a training and testing set from that dataset.\n",
    "    * Build a 3-nearest neighbor model and train it on the training set.\n",
    "    * With that trained model, make predictions on both the training and testing sets.\n",
    "    * Evalute the predictions using root-mean-squared-error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edf1c66",
   "metadata": {},
   "source": [
    "### Part A: Simple sklearn (in-sample only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c332a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_small_df = pd.read_csv('datasets/housing_small.csv')\n",
    "housing_small_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_ftrs = housing_small_df.drop(columns='Target')\n",
    "housing_tgt  = housing_small_df[['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn   = neighbors.KNeighborsRegressor(n_neighbors=3)\n",
    "fit   = knn.fit(housing_ftrs, housing_tgt)\n",
    "preds = knn.predict(housing_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or a \"one-liner\" (broken up for readability)\n",
    "preds = (neighbors.KNeighborsRegressor(n_neighbors=3)\n",
    "                  .fit(housing_ftrs, housing_tgt)\n",
    "                  .predict(housing_ftrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_error(housing_tgt, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cce672",
   "metadata": {},
   "source": [
    "### Part B: Simple sklearn (train-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e517cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_small_df = pd.read_csv('datasets/housing_small.csv')\n",
    "print(housing_small_df.columns)\n",
    "\n",
    "housing_ftrs = housing_small_df.drop(columns='Target')\n",
    "housing_tgt  = housing_small_df[['Target']]\n",
    "\n",
    "(train_ftrs, test_ftrs,\n",
    " train_tgt,  test_tgt) = skms.train_test_split(housing_ftrs, housing_tgt, test_size=.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0bbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knr = (neighbors.KNeighborsRegressor(n_neighbors=3)\n",
    "                .fit(train_ftrs, train_tgt))\n",
    "\n",
    "train_preds = knr.predict(train_ftrs)\n",
    "test_preds = knr.predict(test_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = rms_error(train_tgt, train_preds)\n",
    "print('in-sample train rmse: {:0.4f}'.format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938dfcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = rms_error(test_tgt, test_preds)\n",
    "print('test rmse: {:0.4f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc46ab3",
   "metadata": {},
   "source": [
    "# Part 2:  Comparing Models on TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1632ba",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "  * Part A:\n",
    "    * On a train-test split built from `datasets/housing_small.csv`, fit and predict using a `dummy.DummyRegressor`.\n",
    "    * Compute the root-mean-squared-error (RMSE) for training and testing.\n",
    "  * Part B:\n",
    "    * Create a train-test split from `datasets/housing_small.csv`.\n",
    "    * Build and evaluate three different nearest neighbor models (varying the number of neighbors) using RMSE.\n",
    "  * Part C:\n",
    "    * Create a train-test split from `datasets/housing_small.csv`.\n",
    "    * Build and evaluate three different decision tree models (varying the depth of the tree) using RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b112aba",
   "metadata": {},
   "source": [
    "### Part A: Baseline `Predict-the-Mean` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8450fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = (dummy.DummyRegressor(strategy='mean') # default\n",
    "            .fit(train_ftrs, train_tgt))\n",
    "\n",
    "train_preds = base.predict(train_ftrs)\n",
    "test_preds  = base.predict(test_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = rms_error(train_tgt, train_preds)\n",
    "print('in-sample train rmse: {:0.4f}'.format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = rms_error(test_tgt, test_preds)\n",
    "print('test rmse: {:0.4f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77c829",
   "metadata": {},
   "source": [
    "### Part B: Two Nearest Neighbors Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_neighbors in [3,10]:\n",
    "    knr = (neighbors.KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "                    .fit(train_ftrs, train_tgt))\n",
    "\n",
    "    train_preds = knr.predict(train_ftrs)\n",
    "    test_preds = knr.predict(test_ftrs)\n",
    "\n",
    "    train_rmse = rms_error(train_tgt, train_preds)\n",
    "    test_rmse = rms_error(test_tgt, test_preds)\n",
    "\n",
    "    print('kNN(k={:2d}) train/test rmse: {:0.4f} {:0.4f}'.format(n_neighbors, \n",
    "                                                                 train_rmse, \n",
    "                                                                 test_rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c4200",
   "metadata": {},
   "source": [
    "### Part C: Two Decision Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_depth in [1,3]:\n",
    "    dtr = (tree.DecisionTreeRegressor(max_depth=max_depth)\n",
    "               .fit(train_ftrs, train_tgt))\n",
    "\n",
    "    train_preds = dtr.predict(train_ftrs)\n",
    "    test_preds  = dtr.predict(test_ftrs)\n",
    "\n",
    "    train_rmse = rms_error(train_tgt, train_preds)\n",
    "    test_rmse  = rms_error(test_tgt,  test_preds)\n",
    "\n",
    "    print('DT-R(depth={:1d}) train/test rmse: {:0.4f} {:0.4f}'.format(max_depth, \n",
    "                                                                      train_rmse, \n",
    "                                                                      test_rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a452e04",
   "metadata": {},
   "source": [
    "# Part 3: Cross-Validation and Model Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e593520",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "  * Part A:\n",
    "    * Use `skms.cross_val_score` (imported above) to evaluate the RMSE of a 3-nearest neighbors model on `datasets/housing_small.csv`.  You can use `scoring=rmse` to have `cross_val_score` return the necessary values.\n",
    "    * Use `skms.cross_val_score` to evaluate the RMSE of the models you built in Exercise 2.\n",
    "  * Part B:\n",
    "    * Still working with `datasets/housing_small.csv`, find a good value for the number of neighbors by using `make_complexity_curve`.\n",
    "    * With the good number of neighbors, generate a learning curve with `make_learning_curve`.\n",
    "  * Part C:\n",
    "    * Repeat Part B using a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764218b",
   "metadata": {},
   "source": [
    "### Part A: Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a1079",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [dummy.DummyRegressor(strategy='mean'),\n",
    "          neighbors.KNeighborsRegressor(n_neighbors=3),\n",
    "          neighbors.KNeighborsRegressor(n_neighbors=10),\n",
    "          tree.DecisionTreeRegressor(max_depth=1),\n",
    "          tree.DecisionTreeRegressor(max_depth=3)]\n",
    "\n",
    "for model in models:\n",
    "    cvs = skms.cross_val_score(model, housing_ftrs, housing_tgt, scoring=rmse)\n",
    "    print(model, cvs, 'mean ~ std: {:.3f} ~ {:.3f}'.format(cvs.mean(), cvs.std()), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bffb274",
   "metadata": {},
   "source": [
    "### Part B: A Good Hyper + A Learning Curve (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc94eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,1)\n",
    "knn = neighbors.KNeighborsRegressor\n",
    "\n",
    "n_neighbors = range(11)\n",
    "make_complexity_curve(knn(), \"KNN\", 'n_neighbors', n_neighbors, \n",
    "                      housing_ftrs, housing_tgt, ax=axes[0])\n",
    "\n",
    "make_learning_curve(knn(n_neighbors=5), \"KNR(5)\", housing_ftrs, housing_tgt, ax=axes[1])\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e62691",
   "metadata": {},
   "source": [
    "### Part C: A Good Hyper + A Learning Curve (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,1)\n",
    "dtr = tree.DecisionTreeRegressor\n",
    "\n",
    "max_depth = range(1,11)\n",
    "make_complexity_curve(dtr(), \"DT-R\", 'max_depth', max_depth, \n",
    "                      housing_ftrs, housing_tgt, ax=axes[0])\n",
    "\n",
    "make_learning_curve(dtr(max_depth=2), \"DT-R(2)\", housing_ftrs, housing_tgt, ax=axes[1])\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46546fb1",
   "metadata": {},
   "source": [
    "### Add-On:  We'll Be Doing This a Lot:  Function-ify!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306480b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_two_graphs(model, hyper_name, \n",
    "                  hyper_values, hyper_focus):\n",
    "    ' produce two plots for given model, hypers, on housing_ftrs/tgt'\n",
    "    fig, axes = plt.subplots(1,2, figsize=(12,3), sharey=True)\n",
    "    name = model.__name__\n",
    "    args = {hyper_name:hyper_focus}\n",
    "    \n",
    "    make_complexity_curve(model(), name, \n",
    "                          hyper_name, hyper_values, \n",
    "                          housing_ftrs, housing_tgt, ax=axes[0])\n",
    "    label = \"{}({})\".format(name, hyper_focus)\n",
    "    make_learning_curve(model(**args), label, \n",
    "                        housing_ftrs, housing_tgt, ax=axes[1])\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    cvs = skms.cross_val_score(model(**args), \n",
    "                           housing_ftrs, housing_tgt, \n",
    "                           cv=5, scoring=rmse)\n",
    "    print('mean CV(5) RMSE for {} {:0.3f}'.format(label, cvs.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91463b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "do_two_graphs(neighbors.KNeighborsRegressor, 'n_neighbors', range(11), 5)\n",
    "do_two_graphs(tree.DecisionTreeRegressor, 'max_depth', range(1,11), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7b0ba",
   "metadata": {},
   "source": [
    "# Part 4: Now to Improve!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfca184",
   "metadata": {},
   "source": [
    "# Exercise 4:\n",
    "  *  Part A:\n",
    "      * We can train pretty well with more complex models, but they are overfitting. Can we use more examples to smooth things out?  Using the data in `datasets/housing_tall.csv`:\n",
    "        * Reevaluate our baseline mean-only model.\n",
    "        * Find a good nearest neighbors model build a learning curve for it.\n",
    "        * Find a good decision tree model build a learning curve for it.\n",
    "  *  Part B:\n",
    "      * Does adding more features improve our results?  We'll go back to fewer examples, but use a lot more features.  Using the data in `datasets/housing_wide.csv`:\n",
    "        * Find a good nearest neighbors model build a learning curve for it.\n",
    "        * Find a good decision tree model build a learning curve for it.\n",
    "  *  Part C:\n",
    "      * Does it help to be selective about our features?  Using a `RandomForestRegressor` along with `feature_importances_` identify a top-10 set of features and use those to build a model.\n",
    "  *  Part D:\n",
    "      * Does using a lot of features and a lot of examples help?  Using the data in `datasets/housing_full.csv`:\n",
    "        * Find good nearest neighbor and decision tree models.\n",
    "        * Determine if selecting a top-10 set of features (as in Part C) helps.\n",
    "  * Part E:\n",
    "    * How have we done overall?  Using the best model you found for `housing_wide.csv` or `housing_all.csv`, train that model on *all* of the data in that `.csv` file.  Evaluate that trained model on the data in `datasets/housing_hot_wide.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b3a4f",
   "metadata": {},
   "source": [
    "### Part A: More Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tall_df = pd.read_csv('datasets/housing_tall.csv')\n",
    "print(len(housing_tall_df.columns))\n",
    "\n",
    "print(all(housing_small_df.columns == housing_tall_df.columns),\n",
    "      len(housing_small_df),\n",
    "      len(housing_tall_df))\n",
    "\n",
    "housing_ftrs = housing_tall_df.drop(columns='Target')\n",
    "housing_tgt  = housing_tall_df[['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with more examples, we should have a better estimate of the mean so we need to redo baseline\n",
    "#           also: let's use cv to estimate error so we are 100% comparing apples to apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25dceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = dummy.DummyRegressor(strategy='mean')\n",
    "cvs = skms.cross_val_score(base, \n",
    "                           housing_ftrs, housing_tgt, \n",
    "                           cv=5, scoring=rmse)\n",
    "print('baseline mean 5-fold CV RMSE:', cvs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_two_graphs(neighbors.KNeighborsRegressor, 'n_neighbors', range(11), 5)\n",
    "do_two_graphs(tree.DecisionTreeRegressor, 'max_depth', range(1,11), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed99b2e",
   "metadata": {},
   "source": [
    "### Part B: More Features (back to shorter dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_wide_df = pd.read_csv('datasets/housing_wide.csv')\n",
    "print(len(housing_wide_df.columns))\n",
    "\n",
    "housing_ftrs = housing_wide_df.drop(columns='Target')\n",
    "housing_tgt  = housing_wide_df[['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8be8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_two_graphs(neighbors.KNeighborsRegressor, 'n_neighbors', range(11), 5)\n",
    "do_two_graphs(tree.DecisionTreeRegressor, 'max_depth', range(1,11), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8049a",
   "metadata": {},
   "source": [
    "### Part C: Let's Be Selective about our Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47d1eeb",
   "metadata": {},
   "source": [
    "##### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ac203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()\n",
    "forest.fit(housing_ftrs, housing_tgt)\n",
    "fis = forest.feature_importances_\n",
    "fis = pd.Series(fis, index=housing_ftrs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df = (pd.DataFrame({'ftr_imp':fis})\n",
    "            .sort_values(by='ftr_imp', ascending=False))\n",
    "print(len(imp_df))\n",
    "imp_df[:10].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf45e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imp_df[:10].plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfi = imp_df[:10].index\n",
    "hfi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feebaac5",
   "metadata": {},
   "source": [
    "##### Using \"good\" Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_ftrs = housing_wide_df[hfi]\n",
    "housing_tgt  = housing_wide_df[['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_two_graphs(neighbors.KNeighborsRegressor, 'n_neighbors', range(11), 5)\n",
    "do_two_graphs(tree.DecisionTreeRegressor, 'max_depth', range(1,11), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb35f6",
   "metadata": {},
   "source": [
    "### Part D:  All the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_full_df = pd.read_csv('datasets/housing_full.csv')\n",
    "print(len(housing_full_df.columns))\n",
    "\n",
    "housing_ftrs = housing_full_df.drop(columns='Target')\n",
    "housing_tgt  = housing_full_df[['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_two_graphs(neighbors.KNeighborsRegressor, 'n_neighbors', range(11), 5)\n",
    "do_two_graphs(tree.DecisionTreeRegressor, 'max_depth', range(1,11), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334dbb6",
   "metadata": {},
   "source": [
    "##### Zoom In (Again) on Good Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba3ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()\n",
    "forest.fit(housing_ftrs, housing_tgt)\n",
    "fis = forest.feature_importances_\n",
    "fis = pd.Series(fis, index=housing_ftrs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_df = (pd.DataFrame({'ftr_imp':fis})\n",
    "            .sort_values(by='ftr_imp', ascending=False))\n",
    "print(len(imp_df))\n",
    "imp_df[:10].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd389af",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfi = imp_df[:10].index\n",
    "hfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_ftrs = housing_full_df[hfi]\n",
    "housing_tgt  = housing_full_df[['Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8958289",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_two_graphs(neighbors.KNeighborsRegressor, 'n_neighbors', range(11), 5)\n",
    "do_two_graphs(tree.DecisionTreeRegressor, 'max_depth', range(1,11), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d957e8",
   "metadata": {},
   "source": [
    "### Part E: Train on All Data and Evaluate on Hold-Out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_hot_df = pd.read_csv('datasets/housing_hot_wide.csv')\n",
    "\n",
    "hot_ftrs = housing_hot_df.drop(columns='Target')[hfi]\n",
    "hot_tgt  = housing_hot_df[['Target']]\n",
    "\n",
    "print(len(hot_ftrs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_preds = (neighbors.KNeighborsRegressor(n_neighbors=5)\n",
    "                    .fit(housing_ftrs, housing_tgt)\n",
    "                    .predict(hot_ftrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc045dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_error(hot_tgt, hot_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f215c34",
   "metadata": {},
   "source": [
    "# Bonus:  And Some Ensemble Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5949e828",
   "metadata": {},
   "source": [
    "##### Boosted Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac0058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boosting reduces bias (allows more complexity, less underfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8a2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = ensemble.GradientBoostingRegressor\n",
    "\n",
    "n_estimators = np.arange(1,10) * 10\n",
    "gs = skms.GridSearchCV(gbr(), {'n_estimators':n_estimators}, scoring=rmse, cv=5)\n",
    "gs.fit(housing_ftrs, housing_tgt)\n",
    "\n",
    "param_df = pd.DataFrame.from_records(gs.cv_results_['params'])\n",
    "param_df['mean_rmse'] = gs.cv_results_['mean_test_score']\n",
    "param_df.sort_values('mean_rmse').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e17965",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = skms.cross_val_score(gbr(n_estimators=90), \n",
    "                           housing_ftrs, housing_tgt, \n",
    "                           cv=5, scoring=rmse)\n",
    "print('mean 5-fold CV RMSE:', cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a36e1",
   "metadata": {},
   "source": [
    "##### Bagged Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a33e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFR (bagging reduces bias and variance:  improves both under and overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6,3))\n",
    "rfr = ensemble.RandomForestRegressor # default = 100 estimators\n",
    "make_learning_curve(rfr(), \"RFR(default)\", housing_ftrs, housing_tgt, ax=plt.gca());\n",
    "\n",
    "cvs = skms.cross_val_score(rfr(), \n",
    "                           housing_ftrs, housing_tgt, \n",
    "                           cv=5, scoring=rmse)\n",
    "print('mean 5-fold CV RMSE:', cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17befeb3",
   "metadata": {},
   "source": [
    "# Train on All Data and Evaluate on Hold-Out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251328a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_hot_df = pd.read_csv('datasets/housing_hot_wide.csv')\n",
    "\n",
    "hot_ftrs = housing_hot_df.drop(columns='Target')[hfi]\n",
    "hot_tgt  = housing_hot_df[['Target']]\n",
    "\n",
    "print(len(hot_ftrs.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca8d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_preds = (ensemble.RandomForestRegressor()\n",
    "                    .fit(housing_ftrs, housing_tgt)\n",
    "                    .predict(hot_ftrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e206cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_error(hot_tgt, hot_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
